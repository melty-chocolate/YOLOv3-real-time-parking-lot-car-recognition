{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Write a Download Script\n",
    "Write a script or function that downloads a .ts file and extracts the first frame as a jpg image.\n",
    "\n",
    "example script\n",
    "\n",
    "​> ​./fetch-and-extract 1538076003\n",
    "\n",
    "downloading https://hiring.verkada.com/video/1538076003.ts...\n",
    "\n",
    "extracting image... wrote 1538076003.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://hiring.verkada.com/video/1538084161.ts\n",
      "extracting image...wrote ./image/1538084161.jpg\n",
      "downloading https://hiring.verkada.com/video/1538084400.ts\n",
      "extracting image...wrote ./image/1538084400.jpg\n",
      "downloading https://hiring.verkada.com/video/1538084640.ts\n",
      "extracting image...wrote ./image/1538084640.jpg\n",
      "downloading https://hiring.verkada.com/video/1538084880.ts\n",
      "extracting image...wrote ./image/1538084880.jpg\n",
      "downloading https://hiring.verkada.com/video/1538085120.ts\n",
      "extracting image...wrote ./image/1538085120.jpg\n",
      "downloading https://hiring.verkada.com/video/1538085360.ts\n",
      "extracting image...wrote ./image/1538085360.jpg\n",
      "downloading https://hiring.verkada.com/video/1538085600.ts\n",
      "extracting image...wrote ./image/1538085600.jpg\n",
      "downloading https://hiring.verkada.com/video/1538085840.ts\n",
      "extracting image...wrote ./image/1538085840.jpg\n",
      "downloading https://hiring.verkada.com/video/1538086080.ts\n",
      "extracting image...wrote ./image/1538086080.jpg\n",
      "downloading https://hiring.verkada.com/video/1538086320.ts\n",
      "extracting image...wrote ./image/1538086320.jpg\n",
      "downloading https://hiring.verkada.com/video/1538086560.ts\n",
      "extracting image...wrote ./image/1538086560.jpg\n",
      "downloading https://hiring.verkada.com/video/1538086800.ts\n",
      "extracting image...wrote ./image/1538086800.jpg\n",
      "downloading https://hiring.verkada.com/video/1538087040.ts\n",
      "extracting image...wrote ./image/1538087040.jpg\n",
      "downloading https://hiring.verkada.com/video/1538087280.ts\n",
      "extracting image...wrote ./image/1538087280.jpg\n",
      "downloading https://hiring.verkada.com/video/1538087520.ts\n",
      "extracting image...wrote ./image/1538087520.jpg\n",
      "downloading https://hiring.verkada.com/video/1538087760.ts\n",
      "extracting image...wrote ./image/1538087760.jpg\n",
      "downloading https://hiring.verkada.com/video/1538088000.ts\n",
      "extracting image...wrote ./image/1538088000.jpg\n",
      "downloading https://hiring.verkada.com/video/1538088239.ts\n",
      "extracting image...wrote ./image/1538088239.jpg\n",
      "downloading https://hiring.verkada.com/video/1538088479.ts\n",
      "extracting image...wrote ./image/1538088479.jpg\n",
      "downloading https://hiring.verkada.com/video/1538088719.ts\n",
      "extracting image...wrote ./image/1538088719.jpg\n",
      "downloading https://hiring.verkada.com/video/1538088959.ts\n",
      "extracting image...wrote ./image/1538088959.jpg\n",
      "downloading https://hiring.verkada.com/video/1538089199.ts\n",
      "extracting image...wrote ./image/1538089199.jpg\n",
      "downloading https://hiring.verkada.com/video/1538089439.ts\n",
      "extracting image...wrote ./image/1538089439.jpg\n",
      "downloading https://hiring.verkada.com/video/1538089679.ts\n",
      "extracting image...wrote ./image/1538089679.jpg\n",
      "downloading https://hiring.verkada.com/video/1538089919.ts\n",
      "extracting image...wrote ./image/1538089919.jpg\n",
      "downloading https://hiring.verkada.com/video/1538090159.ts\n",
      "extracting image...wrote ./image/1538090159.jpg\n",
      "downloading https://hiring.verkada.com/video/1538090399.ts\n",
      "extracting image...wrote ./image/1538090399.jpg\n",
      "downloading https://hiring.verkada.com/video/1538090639.ts\n",
      "extracting image...wrote ./image/1538090639.jpg\n",
      "downloading https://hiring.verkada.com/video/1538090879.ts\n",
      "extracting image...wrote ./image/1538090879.jpg\n",
      "downloading https://hiring.verkada.com/video/1538091119.ts\n",
      "extracting image...wrote ./image/1538091119.jpg\n",
      "downloading https://hiring.verkada.com/video/1538091358.ts\n",
      "extracting image...wrote ./image/1538091358.jpg\n",
      "downloading https://hiring.verkada.com/video/1538091598.ts\n",
      "extracting image...wrote ./image/1538091598.jpg\n",
      "downloading https://hiring.verkada.com/video/1538091838.ts\n",
      "extracting image...wrote ./image/1538091838.jpg\n",
      "downloading https://hiring.verkada.com/video/1538092078.ts\n",
      "extracting image...wrote ./image/1538092078.jpg\n",
      "downloading https://hiring.verkada.com/video/1538092318.ts\n",
      "extracting image...wrote ./image/1538092318.jpg\n",
      "downloading https://hiring.verkada.com/video/1538092558.ts\n",
      "extracting image...wrote ./image/1538092558.jpg\n",
      "downloading https://hiring.verkada.com/video/1538092798.ts\n",
      "extracting image...wrote ./image/1538092798.jpg\n",
      "downloading https://hiring.verkada.com/video/1538093038.ts\n",
      "extracting image...wrote ./image/1538093038.jpg\n",
      "downloading https://hiring.verkada.com/video/1538093278.ts\n",
      "extracting image...wrote ./image/1538093278.jpg\n",
      "downloading https://hiring.verkada.com/video/1538093518.ts\n",
      "extracting image...wrote ./image/1538093518.jpg\n",
      "downloading https://hiring.verkada.com/video/1538093758.ts\n",
      "extracting image...wrote ./image/1538093758.jpg\n",
      "downloading https://hiring.verkada.com/video/1538093998.ts\n",
      "extracting image...wrote ./image/1538093998.jpg\n",
      "downloading https://hiring.verkada.com/video/1538094238.ts\n",
      "extracting image...wrote ./image/1538094238.jpg\n",
      "downloading https://hiring.verkada.com/video/1538094478.ts\n",
      "extracting image...wrote ./image/1538094478.jpg\n",
      "downloading https://hiring.verkada.com/video/1538094718.ts\n",
      "extracting image...wrote ./image/1538094718.jpg\n",
      "downloading https://hiring.verkada.com/video/1538094957.ts\n",
      "extracting image...wrote ./image/1538094957.jpg\n",
      "downloading https://hiring.verkada.com/video/1538095197.ts\n",
      "extracting image...wrote ./image/1538095197.jpg\n",
      "downloading https://hiring.verkada.com/video/1538095437.ts\n",
      "extracting image...wrote ./image/1538095437.jpg\n",
      "downloading https://hiring.verkada.com/video/1538095677.ts\n",
      "extracting image...wrote ./image/1538095677.jpg\n",
      "downloading https://hiring.verkada.com/video/1538095917.ts\n",
      "extracting image...wrote ./image/1538095917.jpg\n",
      "downloading https://hiring.verkada.com/video/1538096157.ts\n",
      "extracting image...wrote ./image/1538096157.jpg\n",
      "downloading https://hiring.verkada.com/video/1538096397.ts\n",
      "extracting image...wrote ./image/1538096397.jpg\n",
      "downloading https://hiring.verkada.com/video/1538096637.ts\n",
      "extracting image...wrote ./image/1538096637.jpg\n",
      "downloading https://hiring.verkada.com/video/1538096877.ts\n",
      "extracting image...wrote ./image/1538096877.jpg\n",
      "downloading https://hiring.verkada.com/video/1538097117.ts\n",
      "extracting image...wrote ./image/1538097117.jpg\n",
      "downloading https://hiring.verkada.com/video/1538097357.ts\n",
      "extracting image...wrote ./image/1538097357.jpg\n",
      "downloading https://hiring.verkada.com/video/1538097597.ts\n",
      "extracting image...wrote ./image/1538097597.jpg\n",
      "downloading https://hiring.verkada.com/video/1538097837.ts\n",
      "extracting image...wrote ./image/1538097837.jpg\n",
      "downloading https://hiring.verkada.com/video/1538098077.ts\n",
      "extracting image...wrote ./image/1538098077.jpg\n",
      "downloading https://hiring.verkada.com/video/1538098316.ts\n",
      "extracting image...wrote ./image/1538098316.jpg\n",
      "downloading https://hiring.verkada.com/video/1538098556.ts\n",
      "extracting image...wrote ./image/1538098556.jpg\n",
      "downloading https://hiring.verkada.com/video/1538098796.ts\n",
      "extracting image...wrote ./image/1538098796.jpg\n",
      "downloading https://hiring.verkada.com/video/1538099036.ts\n",
      "extracting image...wrote ./image/1538099036.jpg\n",
      "downloading https://hiring.verkada.com/video/1538099276.ts\n",
      "extracting image...wrote ./image/1538099276.jpg\n",
      "downloading https://hiring.verkada.com/video/1538099516.ts\n",
      "extracting image...wrote ./image/1538099516.jpg\n",
      "downloading https://hiring.verkada.com/video/1538099756.ts\n",
      "extracting image...wrote ./image/1538099756.jpg\n",
      "downloading https://hiring.verkada.com/video/1538099996.ts\n",
      "extracting image...wrote ./image/1538099996.jpg\n",
      "downloading https://hiring.verkada.com/video/1538100236.ts\n",
      "extracting image...wrote ./image/1538100236.jpg\n",
      "downloading https://hiring.verkada.com/video/1538100476.ts\n",
      "extracting image...wrote ./image/1538100476.jpg\n",
      "downloading https://hiring.verkada.com/video/1538100716.ts\n",
      "extracting image...wrote ./image/1538100716.jpg\n",
      "downloading https://hiring.verkada.com/video/1538100956.ts\n",
      "extracting image...wrote ./image/1538100956.jpg\n",
      "downloading https://hiring.verkada.com/video/1538101196.ts\n",
      "extracting image...wrote ./image/1538101196.jpg\n",
      "downloading https://hiring.verkada.com/video/1538101436.ts\n",
      "extracting image...wrote ./image/1538101436.jpg\n",
      "downloading https://hiring.verkada.com/video/1538101676.ts\n",
      "extracting image...wrote ./image/1538101676.jpg\n",
      "downloading https://hiring.verkada.com/video/1538101916.ts\n",
      "extracting image...wrote ./image/1538101916.jpg\n",
      "downloading https://hiring.verkada.com/video/1538102156.ts\n",
      "extracting image...wrote ./image/1538102156.jpg\n",
      "downloading https://hiring.verkada.com/video/1538102396.ts\n",
      "extracting image...wrote ./image/1538102396.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://hiring.verkada.com/video/1538102636.ts\n",
      "extracting image...wrote ./image/1538102636.jpg\n",
      "downloading https://hiring.verkada.com/video/1538102876.ts\n",
      "extracting image...wrote ./image/1538102876.jpg\n",
      "downloading https://hiring.verkada.com/video/1538103116.ts\n",
      "extracting image...wrote ./image/1538103116.jpg\n",
      "downloading https://hiring.verkada.com/video/1538103356.ts\n",
      "extracting image...wrote ./image/1538103356.jpg\n",
      "downloading https://hiring.verkada.com/video/1538103597.ts\n",
      "extracting image...wrote ./image/1538103597.jpg\n",
      "downloading https://hiring.verkada.com/video/1538103837.ts\n",
      "extracting image...wrote ./image/1538103837.jpg\n",
      "downloading https://hiring.verkada.com/video/1538104077.ts\n",
      "extracting image...wrote ./image/1538104077.jpg\n",
      "downloading https://hiring.verkada.com/video/1538104317.ts\n",
      "extracting image...wrote ./image/1538104317.jpg\n",
      "downloading https://hiring.verkada.com/video/1538104557.ts\n",
      "extracting image...wrote ./image/1538104557.jpg\n",
      "downloading https://hiring.verkada.com/video/1538104797.ts\n",
      "extracting image...wrote ./image/1538104797.jpg\n",
      "downloading https://hiring.verkada.com/video/1538105037.ts\n",
      "extracting image...wrote ./image/1538105037.jpg\n",
      "downloading https://hiring.verkada.com/video/1538105277.ts\n",
      "extracting image...wrote ./image/1538105277.jpg\n",
      "downloading https://hiring.verkada.com/video/1538105517.ts\n",
      "extracting image...wrote ./image/1538105517.jpg\n",
      "downloading https://hiring.verkada.com/video/1538105757.ts\n",
      "extracting image...wrote ./image/1538105757.jpg\n",
      "downloading https://hiring.verkada.com/video/1538105997.ts\n",
      "extracting image...wrote ./image/1538105997.jpg\n",
      "downloading https://hiring.verkada.com/video/1538106237.ts\n",
      "extracting image...wrote ./image/1538106237.jpg\n",
      "downloading https://hiring.verkada.com/video/1538106477.ts\n",
      "extracting image...wrote ./image/1538106477.jpg\n",
      "downloading https://hiring.verkada.com/video/1538106717.ts\n",
      "extracting image...wrote ./image/1538106717.jpg\n",
      "downloading https://hiring.verkada.com/video/1538106957.ts\n",
      "extracting image...wrote ./image/1538106957.jpg\n",
      "downloading https://hiring.verkada.com/video/1538107197.ts\n",
      "extracting image...wrote ./image/1538107197.jpg\n",
      "downloading https://hiring.verkada.com/video/1538107437.ts\n",
      "extracting image...wrote ./image/1538107437.jpg\n",
      "downloading https://hiring.verkada.com/video/1538107677.ts\n",
      "extracting image...wrote ./image/1538107677.jpg\n",
      "downloading https://hiring.verkada.com/video/1538107917.ts\n",
      "extracting image...wrote ./image/1538107917.jpg\n"
     ]
    }
   ],
   "source": [
    "filename = 'index.txt'\n",
    "with open(filename) as f:\n",
    "    data = f.readlines()\n",
    "for i in range(2000,8000,60):\n",
    "    timestamp = data[i][:-1]\n",
    "    \n",
    "    # Read the video\n",
    "    cam = cv2.VideoCapture('https://hiring.verkada.com/video/'+timestamp)\n",
    "    print('downloading https://hiring.verkada.com/video/'+timestamp)\n",
    "    try: \n",
    "        # creating a folder named image\n",
    "        if not os.path.exists('image'): \n",
    "            os.makedirs('image') \n",
    "    # if not created then raise error \n",
    "    except OSError: \n",
    "        print ('Error: Creating directory of image') \n",
    "\n",
    "    # reading from frame \n",
    "    ret,frame = cam.read() \n",
    "\n",
    "    if ret: \n",
    "        # if video is still left continue creating images \n",
    "        name = './image/' + timestamp[:-3] + '.jpg'\n",
    "        print ('extracting image...wrote ' + name) \n",
    "\n",
    "        # writing the extracted images \n",
    "        cv2.imwrite(name, frame) \n",
    "\n",
    "    # Release all space and windows once done \n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Extract the car in the box shown above\n",
    "\n",
    "We’ll only look at a single parking spot (the one shown above in the red bounding box). Write a script or function that accepts a single image and runs the yolo3 algorithm (or the algorithm of your choice) on the spot above.\n",
    "\n",
    "example script\n",
    "\n",
    "    >./has-car 1538076003.jpg\n",
    "    \n",
    "running yolo3 on 1538076003.jpg...\n",
    "\n",
    "no car detected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters\n",
    "confThreshold = 0.5  #Confidence threshold\n",
    "nmsThreshold = 0.4   #Non-maximum suppression threshold\n",
    "inpWidth = 416       #Width of network's input image\n",
    "inpHeight = 416      #Height of network's input image\n",
    "\n",
    "# Load names of classes\n",
    "classesFile = \"darknet/data/coco.names\"\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading YOLO...\n"
     ]
    }
   ],
   "source": [
    "# load pretrained YOLO object detector trained on COCO dataset (80 classes)\n",
    "print('loading YOLO...')\n",
    "net = cv2.dnn.readNetFromDarknet('darknet/cfg/yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# could try setting the preferable target to cv.dnn.DNN_TARGET_OPENCL to run it on a GPU\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_car(image_path):\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    #print('running yolo3 on '+image_path[6:])\n",
    "    \n",
    "    # determine only the *output* layer names that we need from YOLO\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # construct a blob from the input image and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes and\n",
    "    # associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (inpWidth, inpHeight),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability) of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter out weak predictions by ensuring the detected probability is greater than the minimum probability\n",
    "            if confidence > confThreshold:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "\n",
    "   \n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            if x in range(180,210) and y in range(180,210) and classes[classIDs[i]] in ['car','truck']:\n",
    "                # extract car from image\n",
    "                car = image[y:y+h, x:x+w]\n",
    "                #cv2.imwrite('./car/'+image_path[6:], car)\n",
    "                #print('car detected!')\n",
    "                return extract_features(car)\n",
    "\n",
    "        #print('no car detected!')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Compute the similarity between two cars\n",
    "\n",
    "Write a script or function that accepts two images. Assume that both images contain a car. Compute whether or not the image is of the same car. The result should be a boolean.\n",
    "example script\n",
    "\n",
    "       > ./fetch-and-extract 1538076183\n",
    "       > ./fetch-and-extract 1538076179\n",
    "       > ./is-same-car 1538076179.jpg 1538076183.jpg\n",
    "       comparing 1538076179.jpg and 1538076183.jpg... same car!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    \n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp, des = sift.detectAndCompute(image, None)\n",
    "    \n",
    "    return (kp, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_matching(feature, matching):\n",
    "    \n",
    "    if not feature or not matching:\n",
    "        return False\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = feature[0], feature[1]\n",
    "    kp2, des2 = matching[0], matching[1]\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append(m)\n",
    "            \n",
    "    MIN_MATCH_COUNT = 3\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        #print('... same car!')\n",
    "        return True\n",
    "    else:\n",
    "        #print('... different car!')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Put it all together!\n",
    "\n",
    "Write a script or function that accepts a time range and outputs each car that was detected and how long it was parked for (approximately). You’ll probably want to get the index file to see which timestamps are available for download.\n",
    "\n",
    "The output format or return value for all steps is up to you. A possible sample output is shown below for a python shell script:\n",
    "\n",
    "       > curl https://hiring.verkada.com/video/index.txt > index.txt\n",
    "       > python3 analyze-cars.py --index index.txt --start 1538076003 --end 1538078234\n",
    "       \n",
    "       analyzing from 1538076003 to 1538078234\n",
    "       found car at 1538076175. parked until 1538077874 (28 minutes).\n",
    "       ... wrote output/1538076175-28min.jpg\n",
    "       found car at 1538077954. parked until 1538078198 (4 minutes).\n",
    "       ... wrote output/1538077954-4min.jpg\n",
    "       no more cars found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing from 1538084161 to 1538108158\n",
      "found car at 1538084880 parked until 1538097117(207 minutes).\n",
      "...wrote output/1538084880-207min.jpg\n",
      "found car at 1538097597 parked until 1538098556(19 minutes).\n",
      "...wrote output/1538097597-19min.jpg\n",
      "found car at 1538098796 parked until 1538102636(68 minutes).\n",
      "...wrote output/1538098796-68min.jpg\n",
      "found car at 1538102876 parked until 1538104797(36 minutes).\n",
      "...wrote output/1538102876-36min.jpg\n",
      "found car at 1538105517 parked until 1538105997(12 minutes).\n",
      "...wrote output/1538105517-12min.jpg\n"
     ]
    }
   ],
   "source": [
    "filename = 'index.txt'\n",
    "with open(filename) as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "print('analyzing from '+ data[2000][:-4] + ' to ' + data[8000][:-4])\n",
    "\n",
    "images_path = 'image/'\n",
    "files = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
    "\n",
    "# initial state of observed parking spot\n",
    "occupied = False\n",
    "# features of the car parked in this spot, initial None \n",
    "occupied_feature = None\n",
    "start = None\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    cur_car_feature = extract_car(files[i])\n",
    "    if cur_car_feature:   # if there is a car found in this spot in current img\n",
    "        if not occupied:  # if the spot is not occupied\n",
    "            occupied = True\n",
    "            occupied_feature = cur_car_feature\n",
    "            start = files[i][6:-4]\n",
    "            print('found car at ' + start , end = '')\n",
    "        \n",
    "        # if the spot is occupied, then compare these two cars to check if they are same  \n",
    "        else:\n",
    "            # if they are different, calculate the parking time\n",
    "            if not extract_features_matching(cur_car_feature, occupied_feature):\n",
    "                duration = int((int(files[i][6:-4])-int(start))/60)\n",
    "                print(' parked until ' + files[i-1][6:-4] + '(%s minutes).'% duration)\n",
    "                print('...wrote output/'+start+'-%smin.jpg' %duration)\n",
    "                start = files[i][6:-4]\n",
    "                print('found car at ' + start , end = '')\n",
    "            occupied_feature = cur_car_feature\n",
    "    # if there is not car found in this spot in current img\n",
    "    else:\n",
    "        if occupied:\n",
    "            duration = int((int(files[i][6:-4])-int(start))/60)\n",
    "            print(' parked until ' + files[i-1][6:-4] + '(%s minutes).'% duration)\n",
    "            print('...wrote output/'+start+'-%smin.jpg' %duration)\n",
    "\n",
    "            occupied_feature = None\n",
    "            start = None\n",
    "            occupied = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
